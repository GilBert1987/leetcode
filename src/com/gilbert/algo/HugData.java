package com.gilbert.algo;

public class HugData {
    // 1. 海量日志数据，提取出某日访问百度次数最多的那个IP。
    // 思路 hash 算法 多项式相加 字符集合 映射到证书集合

    //h = h * 32 + char[i];
    // h 返回值

    // 数据量 / 内存大小 分片  分不下 文件进行分段
    // 文件内 进行统计排序

    // 输出排序文件
    // 多路归并

    // 数据的每一行都是一个IP 地址



    // Hash
//
//    2.统计最热门的10个查询串

    // Hash 分文件  统计 堆排序
//
//3.有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。
    // 分成1024 和文件 分的方法  对每一个单词做Hash  h = h * 32 + char[i] % 1024 保证每一个文件的文件行数 如果超过 进行分片
    // 小文件中进行统计每一个大小  写入新的文件 1024 个文件
    // K路归并 或者堆排序



//    通过hash_map将1G文件分别存储到1024个小文件中，然后在小文件中进行遍历，单词出现一次加1，得到每个小文件中频数最高的词，将1024个小文件中频数最高的词统计，相同的词频数相加生成集合，对集合进行排序，输出Top100


//
//            4.有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。
//
//            5.在海量数据中找出重复次数最多的一个？
//
//            6.上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。
//
//    int数字的重复数据查找（bitmap）
//
//    在2.5亿个整数中找出不重复的整数（内存不足以容纳这2.5亿个整数）
//
//    腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？
//
//    超大文件取数字交集
//
//            字符串重复
//
//    给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url
    // Hash 分文件

//
//    字符串统计（trie 树）
//
//    一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词
//
//    海量数据中位数（计数排序）
//            ————————————————
//    版权声明：本文为CSDN博主「seeInfinite」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
//    原文链接：https://blog.csdn.net/qq_41058526/article/details/89313852

}
